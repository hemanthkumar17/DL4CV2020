{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL4CV-Assignment-4-Week-7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemanthkumar17/DL4CV2020/blob/main/DL4CV_Assignment_4_Week_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCBjxEJ4qUnn"
      },
      "source": [
        "#### **Welcome to Assignment 3 on Deep Learning for Computer Vision.**\n",
        "This notebook consists of two parts. In Part-1 you'll have to code a Siamese Network, for Part-2 you need to go through a official PyTorch tutorial, understand it and answer some questions.\n",
        "  \n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
        "you should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "3. Read documentation of each function carefully.\n",
        "4. All the Best!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_sQ4DarFOLB"
      },
      "source": [
        "# Part-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJwH6jxrqI-5"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "import timeit\n",
        "\n",
        "## Please DONOT remove these lines. \n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(0)\n",
        "########################\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "# Check availability of GPU and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#### YOUR CODE ENDS HERE ####\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35WMBNIey4z-"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhSvcqdYqJ6U"
      },
      "source": [
        "#### Prepare the dataset for Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stYbGPoLqzDE"
      },
      "source": [
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        \n",
        "        self.train = train\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        # Define a set of transforms for preparing the dataset\n",
        "        mean, std = 0.1307, 0.3081\n",
        "        self.transform =  transforms.Compose([\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Normalize(mean=mean, std=std)\n",
        "        ])# convert the image to a pytorch tensor\n",
        "                          # normalise the images with mean and std of the dataset\n",
        "        \n",
        "        # Load the MNIST training, test datasets using `torchvision.datasets.MNIST\n",
        "        # Set the train parameter to self.train and transform parameter to self.transform\n",
        "        self.dataset = datasets.MNIST('./DL4CV/Week4/', train = self.train, transform = self.transform, download=True)\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        if self.train:\n",
        "            #### YOUR CODE STARTS HERE ####\n",
        "            # assign input (x-values) of training data \n",
        "            self.train_data = self.dataset.train_data\n",
        "            # assign labels of training data \n",
        "            self.train_labels = self.dataset.train_labels \n",
        "            # get the set of all the labels in the dataset\n",
        "            self.labels_all = set(self.train_labels.numpy())\n",
        "            self.label_to_idx = {label: np.where(self.train_labels.numpy() == label)[0]\n",
        "                                     for label in self.labels_all} # assign a unique index to all labels in the dataset and store them in a dictionary \n",
        "\n",
        "            #### YOUR CODE ENDS HERE ####\n",
        "        else:\n",
        "            #### YOUR CODE STARTS HERE ####\n",
        "            # assign input (x-values) of test data \n",
        "            self.test_data = self.dataset.test_data\n",
        "            # assign labels of test data \n",
        "            self.test_labels = self.dataset.test_labels\n",
        "            # get the set of all the labels in the dataset\n",
        "            self.labels_all = set(self.test_labels.numpy())\n",
        "            self.label_to_idx = {label: np.where(self.test_labels.numpy() == label)[0]\n",
        "                                     for label in self.labels_all} # assign a unique index to all labels in the dataset and store them in a dictionary \n",
        "\n",
        "            #### YOUR CODE ENDS HERE ####\n",
        "            # DONOT change this line of code  \n",
        "            random_state = np.random.RandomState(0)\n",
        "\n",
        "            positive_samples = [] # this will be a list of lists\n",
        "            for ind in range(0, len(self.test_data), 2):\n",
        "              positive_samples.append([ind, random_state.choice(self.label_to_idx[self.test_labels[ind].item()]), 1])\n",
        "            \n",
        "            negative_samples = []\n",
        "            for ind in range(1, len(self.test_data), 2):\n",
        "              negative_samples.append([ind, random_state.choice(self.label_to_idx[np.random.choice(\n",
        "                                                           list(self.labels_all - set([self.test_labels[ind].item()])))]), 0])\n",
        "            \n",
        "            # combine both positive and negative samples into a single variable\n",
        "            #### YOUR CODE STARTS HERE ####\n",
        "            self.test_samples = positive_samples + negative_samples \n",
        "            #### YOUR CODE ENDS HERE ####\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            target = np.random.randint(0, 2)\n",
        "            first_image, first_label = self.train_data[index], self.train_labels[index].item()\n",
        "            if target == 1:\n",
        "                siamese_index = index\n",
        "                while siamese_index == index:\n",
        "                    siamese_index = np.random.choice(self.label_to_idx[first_label])\n",
        "            else:\n",
        "                siamese_label = np.random.choice(list(self.labels_all - set([first_label])))\n",
        "                siamese_index = np.random.choice(self.label_to_idx[siamese_label])\n",
        "            second_image = self.train_data[siamese_index]\n",
        "        else:\n",
        "            first_image = self.test_data[self.test_samples[index][0]]\n",
        "            second_image = self.test_data[self.test_samples[index][1]]\n",
        "            target = self.test_samples[index][2]\n",
        "        first_image = Image.fromarray(first_image.numpy(), mode='L')\n",
        "        second_image = Image.fromarray(second_image.numpy(), mode='L')\n",
        "        first_image = self.transform(first_image)\n",
        "        second_image = self.transform(second_image)\n",
        "        return (first_image, second_image), target\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gEE-dEarnvg"
      },
      "source": [
        "class EmbeddingNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmbeddingNet, self).__init__()\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        # Define a sequential block as per the instructions below:\n",
        "        # Build three blocks with each block containing: Conv->PReLU->Maxpool layers\n",
        "        # Three conv layers should have 16, 32, 64 output channels respectively\n",
        "        # Use convolution kernel size 3\n",
        "        # For maxpool use a kernel size of 2 and stride of 2\n",
        "\n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        # Define linear->PReLU->linear->PReLU->linear\n",
        "        # The first two linear layers should have 256 and 128 output nodes\n",
        "        # The final FC layer should have 2 nodes\n",
        "        self.fc =nn.Sequential(\n",
        "            nn.Linear(in_features=64 * 4 * 4, out_features=256),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(in_features=256, out_features=128),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(in_features=128, out_features=2),\n",
        "        )\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    def forward(self, x):\n",
        "      #### YOUR CODE STARTS HERE ####\n",
        "        # Define the forward pass, convnet -> fc\n",
        "        output = self.convnet(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc(output)\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        return output"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPIClNjsrz78"
      },
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_net):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.embedding_net = embedding_net\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Call the embedding network for both the inputs and return the output\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        op1 = self.embedding_net(x1)\n",
        "        op2 = self.embedding_net(x2)\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        return op1, op2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzlZzVgmM3hC"
      },
      "source": [
        "$$\n",
        "L\\left(x_{0}, x_{1}, y\\right)=\\frac{1}{2} y\\left\\|f\\left(x_{0}\\right)-f\\left(x_{1}\\right)\\right\\|_{2}^{2}+\\frac{1}{2}(1-y)\\left\\{\\max \\left(0, m-\\left\\|(f\\left(x_{0}\\right)-f\\left(x_{1}) + \\epsilon\\right)\\right\\|_{2}\\right)\\right\\}^{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BclsdWZSr4RK"
      },
      "source": [
        "class ContrastiveLossSiamese(nn.Module):\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(ContrastiveLossSiamese, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.eps = 1e-9\n",
        "\n",
        "    def forward(self, output1, output2, target):\n",
        "        # Use the equation mentioned above to define the loss\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        d = ((output2 - output1).pow(2)).sum(1)\n",
        "        loss_value = 0.5 * target * d + 0.5 * (1 - target).float() * max(0, self.margin - (s + self.eps).sqrt()).pow(2)\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "        loss_value = loss_value.mean()\n",
        "\n",
        "        return loss_value\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVrUkFLmca1I"
      },
      "source": [
        "def train(model, train_loader, device, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        target = target if len(target) > 0 else None\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "        # send the image, target to the device\n",
        "        # data is not a single value here,\n",
        "        # ensure datatype of variable `data` is tuple\n",
        "        target = target.to(device)\n",
        "        data = tuple(d.cuda() for d in data)\n",
        "\n",
        "        # flush out the gradients stored in optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # pass the image to the model and assign the output to variable named outputs\n",
        "        # python star operator will be useful here\n",
        "        # if the datatype of outputs is not a tuple, make it to a tuple\n",
        "\n",
        "        outputs = model(data)\n",
        "\n",
        "        # create inputs to the contrastive loss\n",
        "        # datatype of target should be tuple\n",
        "        loss_inputs = outputs\n",
        "        if target is not None:\n",
        "            target = (target,)\n",
        "            loss_inputs += target\n",
        "\n",
        "        \n",
        "        # calculate the loss using criterion \n",
        "        loss = criterion(loss_inputs)\n",
        "\n",
        "        # append the loss to losses list and update the total_loss variable\n",
        "        losses.append(loss)\n",
        "        total_loss += losses\n",
        "\n",
        "        # do a backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        if batch_idx % 20 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data[0]), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), np.mean(losses)))  \n",
        "    total_loss /= (batch_idx + 1)\n",
        "    print('Average loss on training set: {:.6f}'.format(total_loss))\n",
        "\n",
        "def test(model, test_loader, device, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "          target = target if len(target) > 0 else None\n",
        "          if not type(data) in (tuple, list):\n",
        "              data = (data,)\n",
        "          #### YOUR CODE STARTS HERE ####\n",
        "          # send the image, target to the device\n",
        "          # data is not a single value here,\n",
        "          # ensure datatype of variable `data` is tuple\n",
        "          data = tuple(d.cuda() for d in data)\n",
        "          target = target.to(device)\n",
        "          # pass the image to the model and assign the output to variable named outputs\n",
        "          # python star operator will be useful here\n",
        "          # if the datatype of outputs is not a tuple, make it to a tuple\n",
        "          outputs = model(data)\n",
        "\n",
        "          # create inputs to the contrastive loss\n",
        "          # datatype of target should be tuple\n",
        "          loss_inputs = outputs\n",
        "\n",
        "          # calculate the loss\n",
        "          loss = criterion(loss_inputs)\n",
        "\n",
        "          # update the test+loss variable\n",
        "          test_loss += loss\n",
        "          \n",
        "          #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    print('Average loss on test set: {:.6f}'.format(test_loss))\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw476aRB960E"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDZAVVWVcAC5",
        "outputId": "bc70c3ed-70c2-4cb2-cebe-1964b17ac229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# define the training and test sets\n",
        "# use SiameseDataset\n",
        "mean, std = 0.1307, 0.3081\n",
        "\n",
        "train_dataset = SiameseDataset(train=True)\n",
        "test_dataset = SiameseDataset(train=False)\n",
        "\n",
        "# create dataloaders for training and test datasets\n",
        "# use a batch size of 128 and set shuffle=True for the training set, set num_workers to 2 and pin_memory to True\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "margin = 1.\n",
        "# create a instance of the embedding network and pass it as input to Siamese network\n",
        "embedding_net = EmbeddingNet()\n",
        "model = SiameseNetwork(embedding_net)\n",
        "model.to(device)\n",
        "# define the contrative loss with the specified margin\n",
        "criterion = ContrastiveLossSiamese(margin)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejgunVGzJPK",
        "outputId": "81e97bc9-22b6-462e-ded3-b7e923c9c272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "start = timeit.default_timer()\n",
        "for epoch in range(1, 5):\n",
        "  train(model, train_dataloader, device, optimizer, criterion, epoch)\n",
        "  test(model, test_dataloader, device, criterion)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Total time taken: {} seconds'.format(int(stop - start)) )"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-3f3e919da2ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-ca68e7bd51d3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, device, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# if the datatype of outputs is not a tuple, make it to a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# create inputs to the contrastive loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x2'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S0vb38a_o_r"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "Run the code cell above and report the average loss on the test set loss (If you are not getting the exact number shown in options, please report the closest number).\n",
        "1. 0.03\n",
        "2. 0.3\n",
        "3. 0.001\n",
        "4. 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oP275cQFPvA"
      },
      "source": [
        "# Part-2\n",
        "\n",
        "For Part-2, go through the [Torchvision Object Detection Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html) and ensure you understand the tutorial completely!\n",
        "\n",
        "After you have completely gone through the tutorial answer the following questions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtaG0iORIXid"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Consider the metrics `AP@IoU=0.5` and `AP@IoU=0.75` used in the tutorial. Which of the following statements is True?  \n",
        "\n",
        "1. `IoU@0.75` will always be less than `IoU@0.5`\n",
        "2. `IoU@0.75` will always be  greater than `IoU@0.5` \n",
        "3. `IoU@0.75` need not be always be less than `IoU@0.5`\n",
        "4. `IoU@0.75` need not always be  greater than `IoU@0.5` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9yyqsuyPAMv"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Tutorial uses a network that is pre-trained on COCO dataset. Will training this model from scratch improve the performance? (Hint: You don't really have to re-train the model for this)\n",
        "\n",
        "1. Yes\n",
        "2. No"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71DVEZQf5hr8"
      },
      "source": [
        "print(torch.version.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBQ1h42BI9Mx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}