{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL4V_Assignment_6_(Week_12)_Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemanthkumar17/DL4CV2020/blob/main/DL4V_Assignment_6_(Week_12)_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEpvOceUf0lE"
      },
      "source": [
        "#### **Welcome to Assignment 6 on Deep Learning for Computer Vision.**\n",
        "In this assignment you will get a chance to implement Projected Gradient Descent and Rotation based Self Supervised Learning Technique .\n",
        "\n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "3. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
        "you sould not change anything else code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "4. Read documentation of each function carefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzaL9YMibBNB"
      },
      "source": [
        "### Question 1 : Implement Projected Gradient Descent\n",
        "\n",
        "Given a sample test image and a pretrained model, generate a corresponding adversarial image using Projected gradient Descent(PGD). The following attack configuration MUST be follwed in order to generate the adversarial image: step size = 2/255, epsilon = 0.3 and number_of_steps = 40. \n",
        " \n",
        "Find out the predicted class when the adversarial image generated in the previous step is fed to the pretrained model?\n",
        "\n",
        "\n",
        "\n",
        "1.   Predicted class: 3\n",
        "2.   Predicted class: 4\n",
        "3.   Predicted class: 5\n",
        "4.   Predicted class: 6\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlqzGiwscpb5"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "epsilons = 0.3\n",
        "pretrained_model = \"/content/lenet_mnist_model.pth\"\n",
        "use_cuda=True\n",
        "\n",
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "        #return F.log_softmax(x, dim=1)\n",
        "\n",
        "# MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])), \n",
        "        batch_size=1, shuffle=True)\n",
        "\n",
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "# Initialize the network\n",
        "model = Net().to(device)\n",
        "\n",
        "# Load the pretrained model\n",
        "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
        "\n",
        "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
        "model.eval()\n",
        "\n",
        "## Implement Projected Gradient Descent algorithm\n",
        "\n",
        "### YOUR CODE STARTS HERE\n",
        "def PGD_attack(data, target, model):\n",
        "\n",
        "    step size = 2/255\n",
        "    eps = 0.3 \n",
        "    num_steps = 40\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(x.device)\n",
        "    targeted = y_target is not None\n",
        "    num_channels = x.shape[1]\n",
        "\n",
        "    for i in range(num_steps):\n",
        "        _x_adv = x_adv.clone().detach().requires_grad_(True)\n",
        "\n",
        "        prediction = model(_x_adv)\n",
        "        loss = loss_fn(prediction, y_target if targeted else y)\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Force the gradient step to be a fixed size in a certain norm\n",
        "                # Note .view() assumes batched image data as 4D tensor\n",
        "            gradients = _x_adv.grad * step_size / _x_adv.grad.view(_x_adv.shape[0], -1)\\\n",
        "                .view(-1, num_channels, 1, 1)\n",
        "\n",
        "            if targeted:\n",
        "                # Targeted: Gradient descent with on the loss of the (incorrect) target label\n",
        "                # w.r.t. the image data\n",
        "                x_adv -= gradients\n",
        "            else:\n",
        "                # Untargeted: Gradient ascent on the loss of the correct label w.r.t.\n",
        "                # the model parameters\n",
        "                x_adv += gradients\n",
        "\n",
        "        # Project back into l_norm ball and correct range\n",
        "        \n",
        "        delta = x_adv - x\n",
        "\n",
        "            # Assume x and x_adv are batched tensors where the first dimension is\n",
        "            # a batch dimension\n",
        "        mask = delta.view(delta.shape[0], -1) <= eps\n",
        "\n",
        "        scaling_factor = delta.view(delta.shape[0], -1)\n",
        "        scaling_factor[mask] = eps\n",
        "\n",
        "            # .view() assumes batched images as a 4D Tensor\n",
        "        delta *= eps / scaling_factor.view(-1, 1, 1, 1)\n",
        "\n",
        "        x_adv = x + delta\n",
        "            \n",
        "        x_adv = x_adv.clamp(*clamp)\n",
        "    \n",
        "    return x_adv.detach        \n",
        "\n",
        "### YOUR CODE ENDS HERE\n",
        "\n",
        "def test( model, device, data, target, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor. Important for Attack\n",
        "    data.requires_grad = True\n",
        "\n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    ### generate the perturbed image using PGD    \n",
        "    perturbed_data = PGD_attack(data, target, model)\n",
        "        \n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    if final_pred.item() == target.item():\n",
        "        correct += 1\n",
        "    else:\n",
        "        pass\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_pred, perturbed_data\n",
        "\n",
        "for data,target, in test_loader:\n",
        "  data = data[0:1,:,:,:]\n",
        "  target = target[0:1]\n",
        "  break\n",
        "\n",
        "\n",
        "pred_adv, adv_ex = test(model, device, data,target, epsilons)\n",
        "print (\"Predicted class for perturbed image: \",pred_adv)\n",
        "\n",
        "#Compute the mean pixel value of the adversarial image\n",
        "#Visualize the adversarial image\n",
        "### YOUR CODE STARTS HERE\n",
        "\n",
        "\n",
        "### YOUR CODE ENDS HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abm7O-0ngxJC"
      },
      "source": [
        "### Question 2 : Visualize The adversarial image generated  using the exactly same setup as in previous question and find out the mean pixel intensity of that adversarial image?\n",
        "\n",
        "\n",
        "1.   0.1570\n",
        "2.   0.1940\n",
        "3.   0.2170\n",
        "4.   0.2390\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcH8ExwPa_fv"
      },
      "source": [
        "### Question:3 Rotation Based Self Supervision Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i90RbhebygQM"
      },
      "source": [
        "\n",
        "Please consider the modified LeNet model with below model definition:\n",
        "\n",
        "Shared layers (1 to 4)\n",
        "\n",
        "\n",
        "1.   Conv layer with 10 output channels and filter size 5\n",
        "2.   Conv layer with 20 output channels and filter size 5\n",
        "3.   Dropout layer\n",
        "4.   Fully connected layer with output size 50\n",
        "5.   Branch out 2 heads i.e. main classification and rotation  classification heads.\n",
        "\n",
        "  *   Takes input from step 4 and outputs 10 dimensions(main class labels) through a fully connected layer\n",
        "  *   Takes input from step 4 and outputs 4 dimensions(rotation class labels) through a fully connected layer\n",
        "\n",
        " \n",
        "\n",
        "This model is basically a Y-shaped model where the trail is shared layers and 2 heads are for main classification and rotation classification. \n",
        "A model with above definition is trained for 20 epochs and the resulting trained model is shared with you. \n",
        "Some steps in the forward function are kept blank for you to fill up. You have to load the model and properly, write those steps in the forward function to be able to run the model. Please note that without these steps properly written, you won't be able to run the model. Once you do this, please answer the below question.\n",
        "\n",
        "What is the model test accuracy on MNIST test dataset?\n",
        "\n",
        "1.  92.37\n",
        "2.  93.62\n",
        "3.  94.49\n",
        "4.  95.91"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGCwb_6by8B6"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Assumes that tensor is (nchannels, height, width)\n",
        "def tensor_rot_90(x):\n",
        "    return x.flip(2).transpose(1, 2)\n",
        "\n",
        "def tensor_rot_180(x):\n",
        "    return x.flip(2).flip(1)\n",
        "\n",
        "def tensor_rot_270(x):\n",
        "    return x.transpose(1, 2).flip(2)\n",
        "\n",
        "def rotate_batch_with_labels(batch, labels):\n",
        "\timages = []\n",
        "\tfor img, label in zip(batch, labels):\n",
        "\t\tif label == 1:\n",
        "\t\t\timg = tensor_rot_90(img)\n",
        "\t\telif label == 2:\n",
        "\t\t\timg = tensor_rot_180(img)\n",
        "\t\telif label == 3:\n",
        "\t\t\timg = tensor_rot_270(img)\n",
        "\t\timages.append(img.unsqueeze(0))\n",
        "\treturn torch.cat(images)\n",
        "\n",
        "def rotate_batch(batch, label):\n",
        "\tif label == 'rand':\n",
        "\t\tlabels = torch.randint(4, (len(batch),), dtype=torch.long)\n",
        "\telif label == 'expand':\n",
        "\t\tlabels = torch.cat([torch.zeros(len(batch), dtype=torch.long),\n",
        "\t\t\t\t\ttorch.zeros(len(batch), dtype=torch.long) + 1,\n",
        "\t\t\t\t\ttorch.zeros(len(batch), dtype=torch.long) + 2,\n",
        "\t\t\t\t\ttorch.zeros(len(batch), dtype=torch.long) + 3])\n",
        "\t\tbatch = batch.repeat((4,1,1,1))\n",
        "\telse:\n",
        "\t\tassert isinstance(label, int)\n",
        "\t\tlabels = torch.zeros((len(batch),), dtype=torch.long) + label\n",
        "\treturn rotate_batch_with_labels(batch, labels), labels\n",
        "\n",
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        self.fc2_ssl = nn.Linear(50, 4)\n",
        "\n",
        "    ### network architecture for classification head: \n",
        "    ### conv1 -> maxpool2D-> Relu->conv2->conv2_drop->maxpool2D->Relu->Reshape->fc1->Relu->dropout->fc2,fc2_ssl\n",
        "    def forward(self, x):\n",
        "        ### YOUR CODE STARTS HERE\n",
        "        \n",
        "        ### YOUR CODE ENDS HERE\n",
        "\n",
        "# MNIST Test dataset and dataloader declaration\n",
        "transform = transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# the datasets\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "# Initialize the network\n",
        "net = Net().to(device)\n",
        "\n",
        "parameters = list(net.parameters())\n",
        "optimizer = optim.SGD(parameters, lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "print('Running...')\n",
        "\n",
        "def train(epoch):\n",
        "    net.train()    \n",
        "    \n",
        "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device)        \n",
        "        labels_full = labels.repeat(4)            \n",
        "        \n",
        "        ## Self supervised head\n",
        "        inputs_ssh, labels_ssh = rotate_batch(inputs, \"expand\")\n",
        "        inputs_ssh, labels_ssh = inputs_ssh.to(device), labels_ssh.to(device)\n",
        "        # outputs_clh , outputs_ssh denotes classification head output and self supervision head output respectively \n",
        "        outputs_clh, outputs_ssh = net(inputs_ssh) \n",
        "        loss = criterion(outputs_clh, labels_full)\n",
        "        loss_ssh = criterion(outputs_ssh, labels_ssh)\n",
        "        loss += loss_ssh\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(('Epoch %d: %f' %(epoch,loss.item())))\n",
        "    torch.save(net, \"ssl_mnist.pt\")\n",
        "\n",
        "\n",
        "## Funtion to compute test accuracy using model already trained with additional self-supervised head..\n",
        "def test():\n",
        "        ### YOUR CODE STARTS HERE\n",
        "        \n",
        "        ### YOUR CODE ENDS HERE\n",
        "\n",
        "### Training Loop\n",
        "#for epoch in range(0, 20):\n",
        "    #train(epoch)\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}